{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bf084e5-2dfe-4c39-91b1-62981ce717a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import trimesh\n",
    "import scipy.io\n",
    "import pyvista as pv\n",
    "from geomloss import SamplesLoss\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from torch.autograd import grad\n",
    "\n",
    "# from point_matching import MatchPoints, deform_mesh\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [16, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "359fcace-e94d-4c26-91e6-78eb946eb19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional:\n",
    "\n",
    "# KeOps library for kernel convolutions -- useless for small datasets\n",
    "#!pip install pykeops \n",
    "use_keops = False # use of \n",
    "\n",
    "# pyvista for displaying 3D graphics\n",
    "#!pip install pyvista[all]\n",
    "use_pyvista = True\n",
    "\n",
    "if use_keops:\n",
    "    from pykeops.torch import LazyTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0424a6d5-1607-4684-bf52-cfe953264c80",
   "metadata": {},
   "source": [
    "### Kernel Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a935e5d9-87be-40f2-8fc9-4d93d7fa5c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Kernel (K(x,y)b)_i = sum_j exp(-|xi-yj|^2/sigma^2)bj\n",
    "def GaussKernel(sigma):\n",
    "    oos2 = 1/sigma**2\n",
    "\n",
    "    def K(x,y,b):\n",
    "        x,y = x[:,None,:],y[None,:,:]\n",
    "        if use_keops:\n",
    "            x,y = LazyTensor(x),LazyTensor(y)\n",
    "\n",
    "        return (-oos2*((x-y)**2).sum(dim=2)).exp()@b\n",
    "    \n",
    "    return K\n",
    "\n",
    "# defines a composite kernel that combines a Gaussian (radial basis function) kernel with a \n",
    "# linear kernel, tailored for use with vectors representing (measure similarity) geometric  \n",
    "# entities (such as normals or directions) in addition to positions.\n",
    "def GaussLinKernel(sigma, lib=\"keops\"):\n",
    "    oos2 = 1/sigma**2\n",
    "    \n",
    "    def K(x,y,u,v,b):\n",
    "        # calculates the similarity based on the Euclidean distance between points  \n",
    "        # x and y in a high-dimensional space\n",
    "        Kxy = torch.exp(-oos2*torch.sum((x[:,None,:]-y[None,:,:])**2,dim=2))\n",
    "        # computes the squared dot product between corresponding vectors u and v \n",
    "        # associated with points x and y, respectively. This part captures the \n",
    "        # similarity in directions (e.g., surface normals) at the points\n",
    "        Sxy = torch.sum(u[:,None,:]*v[None,:,:],dim=2)**2\n",
    "        \n",
    "        # composite kernel\n",
    "        return (Kxy*Sxy)@b\n",
    "    \n",
    "    return K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfca33df-6086-4b5d-a112-68012cfa3c2e",
   "metadata": {},
   "source": [
    "### Ordinary Differential Equations (ODEs) solver and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f59f87d-d920-4006-a72d-80b9eff1d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical integrator for solving ordinary differential equations (ODEs)\n",
    "# solves the Hamiltonian system dynamics during the shape deformation process\n",
    "def RalstonIntegrator(nt=10):\n",
    "    # nt:  number of time steps to divide the integration interval into\n",
    "    def f(ODESystem,x0,deltat=1.0):\n",
    "        # x0: initial conditions (p0, q0)\n",
    "        # deltat: total integration time\n",
    "        x = tuple(map(lambda x:x.clone(), x0))\n",
    "        dt = deltat/nt\n",
    "        for i in range(nt):\n",
    "            # computes the derivatives (system dynamics) of the current state x\n",
    "            xdot = ODESystem(*x)\n",
    "            # temporary state xi = x + (2*dt/3)*xdot\n",
    "            # predicts the system state after two-thirds of the time step, \n",
    "            # guided by the initial derivative\n",
    "            xi = tuple(map(lambda x,xdot:x+(2*dt/3)*xdot,x,xdot))\n",
    "            # derivatives at this intermediate state xi\n",
    "            xdoti = ODESystem(*xi)\n",
    "            # final state for the time step is computed using the \n",
    "            # combination of the initial derivative and the intermediate derivative\n",
    "            # weighted average of the initial and intermediate derivatives to estimate the next state\n",
    "            x = tuple(map(lambda x,xdot,xdoti:x+(.25*dt)*(xdot+3*xdoti),x,xdot,xdoti))\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    return f\n",
    "\n",
    "# function to minimize the loss\n",
    "def Optimize(loss,args,niter=5):\n",
    "    # loss: function to compute the loss given the current set of parameters (args)\n",
    "    # args: p0\n",
    "    optimizer = torch.optim.LBFGS(args)\n",
    "    losses = []\n",
    "    print('performing optimization...')\n",
    "    # repeatedly adjusts the parameters to minimize the loss function\n",
    "    for i in range(niter):\n",
    "        print(\"iteration \",i+1,\"/\",niter)\n",
    "        def closure():\n",
    "            # reset optimizer gradients to 0 (previous data doesn't affect the current update)\n",
    "            optimizer.zero_grad()\n",
    "            # compute loss\n",
    "            L = loss(*args)\n",
    "            losses.append(L.item())\n",
    "            # backprop to compute the gradients of the loss w.r.t the parameters\n",
    "            L.backward()\n",
    "            \n",
    "            return L\n",
    "        \n",
    "        # update optimizer parameters based on the loss\n",
    "        optimizer.step(closure)\n",
    "        \n",
    "    print(\"Done.\")\n",
    "\n",
    "    return args, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd0bb7b-640c-4ae5-8ece-574e752b912e",
   "metadata": {},
   "source": [
    "### Implementation of LDDMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e970a22-f0e0-471a-9f9f-6516f32a2801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function of momentum p and position q to represents the total energy of the system\n",
    "# measures the energy associated with the deformation, using the kernel K \n",
    "# to mediate the influence of points on each other.\n",
    "def Hamiltonian(K):\n",
    "    def H(p,q):\n",
    "        return .5*(p*K(q,q,p)).sum()\n",
    "        \n",
    "    return H\n",
    "\n",
    "# builds the Hamiltonian system that needs to be solved during the \"shooting\" process\n",
    "# calculates the gradients of the Hamiltonian with respect to p and q, \n",
    "# which represent the rates of change of these quantities\n",
    "# the system is defined by -Gq, Gp (gradients)\n",
    "def HamiltonianSystem(K):\n",
    "    H = Hamiltonian(K)\n",
    "    \n",
    "    def HS(p,q):\n",
    "        Gp,Gq = grad(H(p,q),(p,q), create_graph=True)\n",
    "        \n",
    "        return -Gq,Gp\n",
    "        \n",
    "    return HS\n",
    "\n",
    "# integrates the Hamiltonian system over time to find the end state (p, q) \n",
    "# starting from initial conditions (p0, q0)\n",
    "def Shooting(p0, q0, K, deltat=1.0, Integrator=RalstonIntegrator()):\n",
    "    return Integrator(HamiltonianSystem(K),(p0, q0), deltat)\n",
    "\n",
    "# intégration des équations de flot\n",
    "def Flow(x0, p0, q0, K, deltat=1.0, Integrator=RalstonIntegrator()):\n",
    "    HS = HamiltonianSystem(K)\n",
    "    \n",
    "    def FlowEq(x,p,q):\n",
    "        return (K(x,q,p),)+HS(p,q)\n",
    "        \n",
    "    return Integrator(FlowEq,(x0,p0,q0),deltat)[0]\n",
    "\n",
    "# defines the loss function to be minimized, \n",
    "# combining the Hamiltonian (energy of the deformation) \n",
    "# and a data attachment loss \n",
    "def LDDMMloss(q0,K,dataloss,gamma=0.):\n",
    "    # dataloss: measures the discrepancy between the deformed source shape and the target shape\n",
    "    # q0: initial configuration of the source shape\n",
    "    # K: kernel function\n",
    "    # gamma: regularization parameter\n",
    "    def loss(p0):\n",
    "        # finding p0 that minimizes the loss\n",
    "        # p, q: final momentum and deformed shape after the shooting process\n",
    "        p,q = Shooting(p0,q0,K)\n",
    "        # Hamiltonian(K): computes the energy of the initial configuration q0 with the initial momentum p0. \n",
    "        # This represents the energy required to deform the shape regularized by gamma\n",
    "        # dataloss(q): computes the mismatch between the final deformed shape q and the target\n",
    "        return gamma * Hamiltonian(K)(p0,q0) + dataloss(q)\n",
    "    \n",
    "    ############################# ToDo #############################\n",
    "    # when adding contours use the flow function, set deltat parameter\n",
    "    # flow -> dataloss for curve -> flow\n",
    "    # extract contours and get corresponding coordinates in 3D\n",
    "    ###############################################################\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c6ecea-a6ab-4997-a5ef-3e9f066ab97c",
   "metadata": {},
   "source": [
    "### Data attachment function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc9602a4-5df8-4b34-9555-3c9e43a3ca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data attachment function for triangulated surfaces, varifold model\n",
    "# focuses on matching geometric features like positions and normals without requiring explicit \n",
    "# point correspondence. this function is useful when the exact matching of points between shapes \n",
    "# is infeasible or not desired\n",
    "def lossVarifoldSurf(FS,VT,FT,K):\n",
    "    # VT: coordinates of the points of the target surface\n",
    "    # FS,FT: indices of the triangles of the source and target surfaces\n",
    "    # K: varifold kernel\n",
    "    \n",
    "    # compute centers (C), normals (N), and areas (L) of the triangles for a given surface\n",
    "    # based on vertices V and faces F\n",
    "    def CompCLNn(F,V):\n",
    "        # V0, V1, V2: vertices of each triangle\n",
    "        # center(C) of each triangle is calculated as the average of its vertices\n",
    "        # normal(N): taking the cross product of two edges of the triangle, which is then normalized\n",
    "        # area(L): length of the normal vector before normalization\n",
    "        V0, V1, V2 = V.index_select(0,F[:,0]), V.index_select(0,F[:,1]), V.index_select(0,F[:,2])\n",
    "        C, N = .5*(V0+V1+V2), .5*torch.linalg.cross(V1-V0,V2-V0)\n",
    "        L = (N**2).sum(dim=1)[:,None].sqrt()\n",
    "        \n",
    "        return C,L,N/L\n",
    "    \n",
    "    CT,LT,NTn = CompCLNn(FT,VT)\n",
    "    # self-interaction term for the target surface using the varifold kernel  K\n",
    "    cst = (LT*K(CT,CT,NTn,NTn,LT)).sum()\n",
    "    \n",
    "    # calculates the varifold distance between the source and target surfaces\n",
    "    \n",
    "    # loss is formulated as the sum of the source self-interaction and the \n",
    "    # target self-interaction (cst), minus twice the cross term (interaction between their geometric features)\n",
    "    # the intuition is to minimize the difference in geometric features (both position and direction of normals) \n",
    "    # between the source and target surfaces, thereby aligning them\n",
    "    def loss(VS):\n",
    "        CS,LS,NSn = CompCLNn(FS,VS)\n",
    "        \n",
    "        return cst + (LS*K(CS,CS,NSn,NSn,LS)).sum() - 2*(LS*K(CS,CT,NSn,NTn,LT)).sum()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba2c78f-57a2-47ec-a981-2b9a6498a371",
   "metadata": {},
   "source": [
    "### Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7ab5eea-a840-4fde-bb29-ffedbb0d0152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result display function for landmark or point cloud data\n",
    "def PlotRes2D(z, pts=None):\n",
    "    def plotfun(q0,p0,Kv, showgrid=True):\n",
    "        p,q = Shooting(p0,q0,Kv)\n",
    "        q0np, qnp = q0.data.numpy(), q.data.numpy()\n",
    "        q0np, qnp, znp = q0.data.numpy(), q.data.numpy(), z.data.numpy()\n",
    "        plt.plot(znp[:,0],znp[:,1],'.');\n",
    "        plt.plot(q0np[:,0],q0np[:,1],'+');\n",
    "        plt.plot(qnp[:,0],qnp[:,1],'o');\n",
    "        plt.axis('equal');\n",
    "        if showgrid:\n",
    "            X = get_def_grid(p0,q0,Kv)\n",
    "            plt.plot(X[0],X[1],'k',linewidth=.25);\n",
    "            plt.plot(X[0].T,X[1].T,'k',linewidth=.25); \n",
    "        n,d = q0.shape\n",
    "        nt = 20\n",
    "        Q = np.zeros((n,d,nt))\n",
    "        for i in range(nt):\n",
    "            t = i/(nt-1)\n",
    "            Q[:,:,i] = Shooting(t*p0,q0,Kv)[1].data.numpy()\n",
    "        plt.plot(Q[:,0,:].T,Q[:,1,:].T,'y');\n",
    "        if type(pts)!=type(None):\n",
    "            phipts = Flow(pts,p0,q0,Kv).data\n",
    "            plt.plot(phipts.numpy()[:,0],phipts.numpy()[:,1],'.b',markersize=.1);\n",
    "    return plotfun\n",
    "\n",
    "# display function for triangulated surface type data\n",
    "def PlotRes3D(VS, FS, VT, FT, filename=\"deformation.html\"):\n",
    "    def plotfun(q0, p0, Kv, src_opacity=1, tgt_opacity=1, def_opacity=1, showgrid=True):\n",
    "        # q0, p0: Initial vertices and momenta (optimized) for the source shape\n",
    "        # simulate the deformation process and compute the final deformed shape q\n",
    "        p,q = Shooting(p0,q0,Kv)\n",
    "        # q0np, qnp: numpy arrays of the initial and final vertex positions\n",
    "        q0np, qnp = q0.data.numpy(), q.data.numpy()\n",
    "        # numpy arrays of source and target faces\n",
    "        FSnp,VTnp, FTnp = FS.data.numpy(),  VT.data.numpy(), FT.data.numpy() \n",
    "        if use_pyvista:\n",
    "            p = pv.Plotter()\n",
    "            opacity = 1\n",
    "            # mesh for the initial shape\n",
    "            p.add_mesh(surf_to_pv(q0np,FSnp), color='lightblue', opacity=src_opacity)\n",
    "            # mesh for the deformed shape\n",
    "            p.add_mesh(surf_to_pv(qnp,FSnp), color='lightcoral', opacity=def_opacity)\n",
    "            # mesh for target shape\n",
    "            p.add_mesh(surf_to_pv(VTnp,FTnp), color='lightgreen', opacity=tgt_opacity)\n",
    "            if showgrid:\n",
    "                ng = 20\n",
    "                X = get_def_grid(p0,q0,Kv,ng=ng)\n",
    "                for k in range(3):\n",
    "                    for i in range(ng):\n",
    "                        for j in range(ng):\n",
    "                            p.add_mesh(lines_from_points(X[:,i,j,:].T))\n",
    "                    X = X.transpose((0,2,3,1))\n",
    "            # p.show()\n",
    "            p.export_html(filename)\n",
    "            p.close()\n",
    "        else:\n",
    "            fig = plt.figure();\n",
    "            plt.axis('off')\n",
    "            plt.title('LDDMM matching example')     \n",
    "#             ax = Axes3D(fig, auto_add_to_figure=False)\n",
    "            ax = Axes3D(fig)\n",
    "            # triangular mesh for the initial shape\n",
    "            ax.plot_trisurf(q0np[:,0],q0np[:,1],q0np[:,2],triangles=FSnp,alpha=.5)\n",
    "            # triangular mesh for the deformed shape\n",
    "            ax.plot_trisurf(qnp[:,0],qnp[:,1],qnp[:,2],triangles=FSnp,alpha=.5)\n",
    "            # triangular mesh for the target shape\n",
    "            ax.plot_trisurf(VTnp[:,0],VTnp[:,1],VTnp[:,2],triangles=FTnp,alpha=.5)\n",
    "            if showgrid:\n",
    "                ng = 20\n",
    "                X = get_def_grid(p0,q0,Kv,ng=ng)\n",
    "                for k in range(3):\n",
    "                    for i in range(ng):\n",
    "                        for j in range(ng):\n",
    "                            ax.plot(X[0,i,j,:],X[1,i,j,:],X[2,i,j,:],'k',linewidth=.25);\n",
    "                    X = X.transpose((0,2,3,1))\n",
    "            fig.add_axes(ax)\n",
    "    return plotfun\n",
    "\n",
    "def get_def_grid(p0,q0,Kv,ng=50):\n",
    "    d = p0.shape[1]\n",
    "    p,q = Shooting(p0,q0,Kv)\n",
    "    q0np, qnp = q0.data.numpy(), q.data.numpy()\n",
    "    q0np, qnp = q0.data.numpy(), q.data.numpy()\n",
    "    # calculates the minimum (a) and maximum (b) coordinates for the vertices in the \n",
    "    # initial (q0) and final (q) positions to establish the bounds of the grid\n",
    "    a = list(np.min(np.vstack((q0np[:,k],qnp[:,k]))) for k in range(d))\n",
    "    b = list(np.max(np.vstack((q0np[:,k],qnp[:,k]))) for k in range(d))\n",
    "    # expands these bounds by 20% to ensure the grid extends slightly beyond the \n",
    "    # immediate area covered by the initial and deformed shapes\n",
    "    sz = 0.2\n",
    "    lsp = list(np.linspace(a[k]-sz*(b[k]-a[k]),b[k]+sz*(b[k]-a[k]),ng,dtype=np.float32) for k in range(d))\n",
    "    X = np.meshgrid(*lsp)\n",
    "    x = np.concatenate(list(X[k].reshape(ng**d,1) for k in range(d)),axis=1)\n",
    "    # transform grid (x) according to the LDDMM mapping\n",
    "    # Flow():  integrates how each point in the grid moves under the transformation \n",
    "    # defined by Kv, p0, and q0. This step effectively applies the diffeomorphic map to the entire grid\n",
    "    phix = Flow(torch.from_numpy(x),p0,q0,Kv).detach().numpy()\n",
    "    X = phix.transpose().reshape([d]+[ng]*d)\n",
    "    return X\n",
    "\n",
    "def lines_from_points(points):\n",
    "    import pyvista as pv\n",
    "    \"\"\"Given an array of points, make a line set\"\"\"\n",
    "    poly = pv.PolyData()\n",
    "    poly.points = points\n",
    "    cells = np.full((len(points) - 1, 3), 2, dtype=np.int_)\n",
    "    cells[:, 1] = np.arange(0, len(points) - 1, dtype=np.int_)\n",
    "    cells[:, 2] = np.arange(1, len(points), dtype=np.int_)\n",
    "    poly.lines = cells\n",
    "    return poly\n",
    "\n",
    "def surf_to_pv(V,F):\n",
    "    nf = F.shape[0]\n",
    "    F = np.hstack((np.ones((nf,1),dtype=\"int\")*3,F))\n",
    "    F = F.flatten()\n",
    "    surf = pv.PolyData(V,F)\n",
    "    return surf\n",
    "\n",
    "# fonction d'affichage pour des données de type surface triangulée\n",
    "def PlotResSurf(VS,FS,VT,FT):\n",
    "    def plotfun(q0,p0,Kv):\n",
    "        fig = plt.figure();\n",
    "        plt.axis('off')\n",
    "        plt.title('LDDMM matching example')  \n",
    "        p,q = Shooting(p0,q0,Kv)\n",
    "        q0np, qnp = q0.data.numpy(), q.data.numpy()\n",
    "        FSnp,VTnp, FTnp = FS.data.numpy(),  VT.data.numpy(), FT.data.numpy()    \n",
    "        ax = Axes3D(fig, auto_add_to_figure=False)\n",
    "        ax.plot_trisurf(q0np[:,0],q0np[:,1],q0np[:,2],triangles=FSnp,alpha=.5)\n",
    "        ax.plot_trisurf(qnp[:,0],qnp[:,1],qnp[:,2],triangles=FSnp,alpha=.5)\n",
    "        ax.plot_trisurf(VTnp[:,0],VTnp[:,1],VTnp[:,2],triangles=FTnp,alpha=.5)\n",
    "        fig.add_axes(ax)\n",
    "    return plotfun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dafbb4-4de8-495c-8c36-b3f718caf3f7",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "368ccaea-bbb1-4a5c-8ace-1f682cc590ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load mesh and convert to tensors\n",
    "def load_mesh_as_tensors(filepath):\n",
    "    # Load the mesh\n",
    "    mesh = trimesh.load(filepath, process=False)\n",
    "    \n",
    "    # Convert vertices and faces to PyTorch tensors\n",
    "    vertices = torch.tensor(mesh.vertices, dtype=torch.float32)\n",
    "    faces = torch.tensor(mesh.faces, dtype=torch.long)\n",
    "    \n",
    "    return vertices, faces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066e6eb9-82b8-4637-9afb-7caf8e4ac85b",
   "metadata": {},
   "source": [
    "### Surface matching with LDDMM (without constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7fe46d-3900-4f0a-ba91-3e3a36819e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "VS, FS = load_mesh_as_tensors('../../Data/surface_meshes/segmentation_a_mesh_500.ply')\n",
    "VT, FT = load_mesh_as_tensors('../../Data/surface_meshes/segmentation_r_mesh_500.ply')\n",
    "\n",
    "# Save the tensors into a .pt file\n",
    "torch.save((VS, FS, VT, FT), 'vt_tensors/a-r_mesh.pt')\n",
    "\n",
    "VS,FS,VT,FT = torch.load('vt_tensors/a-r_mesh.pt') \n",
    "q0 = VS.clone().detach().requires_grad_(True)\n",
    "Kv = GaussKernel(sigma=20)\n",
    "# multiscale kernel\n",
    "Dataloss = lossVarifoldSurf(FS,VT,FT,GaussLinKernel(sigma=20)) # try smaller values (15-20)\n",
    "loss = LDDMMloss(q0,Kv,Dataloss, gamma=0.1)\n",
    "p0 = torch.zeros(q0.shape, requires_grad=True)\n",
    "\n",
    "p0, losses = Optimize(loss,[p0],niter=10) # 100 iterations\n",
    "# PlotRes3D(VS,FS,VT,FT, filename=\"output/src.html\")(q0,p0[0],Kv,src_opacity=1,tgt_opacity=0,def_opacity=0, showgrid=False)\n",
    "# PlotRes3D(VS,FS,VT,FT)(q0,p0[0],Kv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4ef8763-564b-4e4e-b16d-19dbbde3474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot source shape\n",
    "PlotRes3D(VS,FS,VT,FT, filename=\"output/src.html\")(q0,p0[0],Kv,src_opacity=1,tgt_opacity=0,def_opacity=0, showgrid=False)\n",
    "\n",
    "# plot target shape\n",
    "PlotRes3D(VS,FS,VT,FT, filename=\"output/tgt.html\")(q0,p0[0],Kv,src_opacity=0,tgt_opacity=1,def_opacity=0, showgrid=False)\n",
    "\n",
    "# plot deformed shape\n",
    "PlotRes3D(VS,FS,VT,FT, filename=\"output/deformation.html\")(q0,p0[0],Kv,src_opacity=0,tgt_opacity=0,def_opacity=1, showgrid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e086d46-9e30-42a0-bf77-b425b75155a3",
   "metadata": {},
   "source": [
    "### Iterative LDDMM\n",
    "\n",
    "The approach:\n",
    "\n",
    "for t=0 to nt(timesteps):\n",
    "\n",
    "1. Full 3D Deformation from Sorce (S) to target (T)\n",
    "2. Get mesh at t+1 (M*)\n",
    "3. Extract midsagittal coordinates from M*\n",
    "4. Perform point matching between midsagittal coordinates and rtMRI coordinates (phi)\n",
    "5. Deform M* with phi to get the new mesh at t+1 (M')\n",
    "6. t=t+1 and S=M'\n",
    "7. Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9c48b358",
   "metadata": {},
   "outputs": [],
   "source": [
    "RTMRI_VOXEL_SIZE = (1.9178, 1.9178) \n",
    "VOLUMETRIC_VOXEL_SIZE = (1.6, 1.6)\n",
    "\n",
    "def get_rtMRI_contours(points_rtmri, midsagittal_coords, R):\n",
    "    points_rtmri_pixels = points_rtmri / RTMRI_VOXEL_SIZE\n",
    "    points_midsagittal_pixels = midsagittal_coords / VOLUMETRIC_VOXEL_SIZE\n",
    "    \n",
    "    points_rtmri_pixels = points_rtmri_pixels - np.mean(points_rtmri_pixels, axis=0)\n",
    "    points_midsagittal_pixels = points_midsagittal_pixels - np.mean(points_midsagittal_pixels, axis=0)\n",
    "    \n",
    "    points_rtmri_rigid = (R @ points_rtmri_pixels.T).T + np.mean(points_midsagittal_pixels, axis=0)\n",
    "    \n",
    "    points_rtmri_physical = points_rtmri_rigid * VOLUMETRIC_VOXEL_SIZE\n",
    "    \n",
    "    return points_rtmri_physical\n",
    "\n",
    "def plot_vt_boundary(coords, title, show_grid, fontsize, show_axis):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(coords[:, 0], coords[:, 1], s=1, color='black')\n",
    "    plt.title(title, fontsize=fontsize)\n",
    "    if not show_axis:\n",
    "        plt.axis('off')\n",
    "    if show_grid:\n",
    "        plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def extract_midsagittal_slice(mesh):\n",
    "    # Center the mesh\n",
    "    mesh_center = mesh.vertices.mean(axis=0)\n",
    "    vertices = mesh.vertices\n",
    "\n",
    "    # Compute distances from the x=0 plane\n",
    "    distances = np.abs(vertices[:, 0])\n",
    "\n",
    "    # Define threshold for selecting closest vertices\n",
    "    threshold = 1.5\n",
    "    closest_idxs = np.where(distances <= threshold)[0]\n",
    "\n",
    "    # Extract the closest vertices\n",
    "    closest_vertices = vertices[closest_idxs]\n",
    "\n",
    "    # Project vertices onto the x=0 plane\n",
    "    projected_vertices = closest_vertices.copy()\n",
    "    projected_vertices[:, 0] = 0\n",
    "\n",
    "    # Extract y and z coordinates\n",
    "    coords = projected_vertices[:, 1:3]\n",
    "\n",
    "    # Adjust x-coordinates for mirroring\n",
    "    x_min, x_max = coords[:, 0].min(), coords[:, 0].max()\n",
    "    coords[:, 0] = -(coords[:, 0] - x_max) - x_min\n",
    "\n",
    "    # Center the coordinates\n",
    "    coords[:, 0] -= coords[:, 0].mean()\n",
    "    coords[:, 1] -= coords[:, 1].mean()\n",
    "\n",
    "    plot_vt_boundary(coords, '3D Midsagittal VT Boundary', show_grid=True, fontsize=14, show_axis=True)\n",
    "    \n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2739db01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main iterative algorithm\n",
    "\n",
    "nt = 2 # number of deformation time steps\n",
    "niter = 1 # number of optimization iterations per full deformation\n",
    "\n",
    "# Load the meshes (source: vowel, target: consonant)\n",
    "VS, FS = load_mesh_as_tensors('../../Data/surface_meshes/segmentation_a_mesh_500.ply')\n",
    "VT, FT = load_mesh_as_tensors('../../Data/surface_meshes/segmentation_r_mesh_500.ply')\n",
    "\n",
    "torch.save((VS, FS, VT, FT), 'vt_tensors/a-r_mesh.pt')\n",
    "VS,FS,VT,FT = torch.load('vt_tensors/a-r_mesh.pt')\n",
    "\n",
    "# Initialize the source mesh (S) and define the kernel.\n",
    "current_source = VS.clone().detach().requires_grad_(True)\n",
    "Kv = GaussKernel(sigma=20)\n",
    "\n",
    "# Set up the data attachment loss \n",
    "Dataloss = lossVarifoldSurf(FS, VT, FT, GaussLinKernel(sigma=20))\n",
    "\n",
    "rtMRI_contours = [] #################### to be implemented\n",
    "R = np.load(\"rigid_rotation_matrix.npy\") \n",
    "\n",
    "for t in range(nt):\n",
    "    print(f\"\\n=== Outer Iteration {t+1}/{nt} ===\")\n",
    "\n",
    "    # 1. Full deformation from current_source (S) to target.\n",
    "    loss_func = LDDMMloss(current_source, Kv, Dataloss, gamma=0.9)\n",
    "\n",
    "    # 2. Optimize the initial momentum p0 for the registration.\n",
    "    p0 = torch.zeros_like(current_source, requires_grad=True)\n",
    "    p0_opt, opt_losses = Optimize(loss_func, [p0], niter=niter)\n",
    "\n",
    "    # 3. Compute the deformed mesh (M*) using the optimized momentum.\n",
    "    p_deformed, M_star = Shooting(p0_opt[0], current_source, Kv, deltat=1/nt)\n",
    "\n",
    "    # 4. Extract midsagittal coordinates from M*\n",
    "    M_star_mesh = trimesh.PointCloud(M_star.detach().numpy())\n",
    "    midsagittal_coords = extract_midsagittal_slice(M_star_mesh)\n",
    "\n",
    "    # 5. Perform point matching (phi deformation) between midsagittal coords and the rtMRI contour.\n",
    "    rtMRI_contour = get_rtMRI_contours(rtMRI_contours[t], midsagittal_coords, R)\n",
    "\n",
    "    # plt.figure(figsize=(6, 6))\n",
    "\n",
    "    # plt.scatter(midsagittal_coords[:, 0], midsagittal_coords[:, 1], color='blue', label=\"Midsagittal Boundary\", s=25)\n",
    "    # plt.scatter(rtMRI_contour[:, 0], rtMRI_contour[:, 1], color='red', label=\"Transformed rtMRI Boundary\", s=25)\n",
    "    \n",
    "    # plt.legend()\n",
    "    # plt.title(\"Alignment of Vocal Tract Boundaries\")\n",
    "    # plt.xlabel(\"X Coordinate\")\n",
    "    # plt.ylabel(\"Y Coordinate\")\n",
    "    # plt.show()\n",
    "    \n",
    "    phi = MatchPoints(midsagittal_coords, rtMRI_contour, sigma=20)\n",
    "\n",
    "    # 6. Apply phi to deform M* and get the new mesh M′.\n",
    "    M_prime = deform_mesh(M_star, phi)\n",
    "\n",
    "    # 7. Update current_source with M′ for the next iteration.\n",
    "    current_source = M_prime.clone().detach().requires_grad_(True)\n",
    "\n",
    "    print(f\"Iteration {t+1} complete. (Updated mesh has {current_source.shape[0]} vertices)\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
