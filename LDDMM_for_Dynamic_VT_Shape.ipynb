{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bf084e5-2dfe-4c39-91b1-62981ce717a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import trimesh\n",
    "import pyvista as pv\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from torch.autograd import grad\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [16, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "359fcace-e94d-4c26-91e6-78eb946eb19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional:\n",
    "\n",
    "# KeOps library for kernel convolutions -- useless for small datasets\n",
    "#!pip install pykeops \n",
    "use_keops = False # use of \n",
    "\n",
    "# pyvista for displaying 3D graphics\n",
    "#!pip install pyvista[all]\n",
    "use_pyvista = True\n",
    "\n",
    "if use_keops:\n",
    "    from pykeops.torch import LazyTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0424a6d5-1607-4684-bf52-cfe953264c80",
   "metadata": {},
   "source": [
    "### Kernel Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a935e5d9-87be-40f2-8fc9-4d93d7fa5c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Kernel (K(x,y)b)_i = sum_j exp(-|xi-yj|^2/sigma^2)bj\n",
    "def GaussKernel(sigma):\n",
    "    oos2 = 1/sigma**2\n",
    "    def K(x,y,b):\n",
    "        x,y = x[:,None,:],y[None,:,:]\n",
    "        if use_keops:\n",
    "            x,y = LazyTensor(x),LazyTensor(y)\n",
    "        return (-oos2*((x-y)**2).sum(dim=2)).exp()@b\n",
    "    return K\n",
    "\n",
    "# Cauchy (K(x,y)b)_i = sum_j (1/(1+|xi-yj|^2/sigma^2))bj\n",
    "def CauchyKernel(sigma):\n",
    "    oos2 = 1/sigma**2\n",
    "    def K(x,y,b):\n",
    "        return (1/(1+oos2*torch.sum((x[:,None,:]-y[None,:,:])**2,dim=2)))@b\n",
    "    return K\n",
    "\n",
    "# kernel with multiple sigmas\n",
    "def SumKernel(*kernels):\n",
    "    def K(*args):\n",
    "        return sum(k(*args) for k in kernels)\n",
    "    return K\n",
    "\n",
    "# defines a composite kernel that combines a Gaussian (radial basis function) kernel with a \n",
    "# linear kernel, tailored for use with vectors representing (measure similarity) geometric  \n",
    "# entities (such as normals or directions) in addition to positions.\n",
    "def GaussLinKernel(sigma,lib=\"keops\"):\n",
    "    oos2 = 1/sigma**2\n",
    "    \n",
    "    def K(x,y,u,v,b):\n",
    "        # calculates the similarity based on the Euclidean distance between points  \n",
    "        # x and y in a high-dimensional space\n",
    "        Kxy = torch.exp(-oos2*torch.sum((x[:,None,:]-y[None,:,:])**2,dim=2))\n",
    "        # computes the squared dot product between corresponding vectors u and v \n",
    "        # associated with points x and y, respectively. This part captures the \n",
    "        # similarity in directions (e.g., surface normals) at the points\n",
    "        Sxy = torch.sum(u[:,None,:]*v[None,:,:],dim=2)**2\n",
    "        \n",
    "        # composite kernel\n",
    "        return (Kxy*Sxy)@b\n",
    "    return K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfca33df-6086-4b5d-a112-68012cfa3c2e",
   "metadata": {},
   "source": [
    "### Ordinary Differential Equations (ODEs) solver and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f59f87d-d920-4006-a72d-80b9eff1d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical integrator for solving ordinary differential equations (ODEs)\n",
    "# solves the Hamiltonian system dynamics during the shape deformation process\n",
    "def RalstonIntegrator(nt=10):\n",
    "    # nt:  number of time steps to divide the integration interval into\n",
    "    def f(ODESystem,x0,deltat=1.0):\n",
    "        # x0: initial conditions (p0, q0)\n",
    "        # deltat: total integration time\n",
    "        x = tuple(map(lambda x:x.clone(),x0))\n",
    "        dt = deltat/nt\n",
    "        for i in range(nt):\n",
    "            # computes the derivatives (system dynamics) of the current state x\n",
    "            xdot = ODESystem(*x)\n",
    "            # temporary state xi = x + (2*dt/3)*xdot\n",
    "            # predicts the system state after two-thirds of the time step, \n",
    "            # guided by the initial derivative\n",
    "            xi = tuple(map(lambda x,xdot:x+(2*dt/3)*xdot,x,xdot))\n",
    "            # derivatives at this intermediate state xi\n",
    "            xdoti = ODESystem(*xi)\n",
    "            # final state for the time step is computed using the \n",
    "            # combination of the initial derivative and the intermediate derivative\n",
    "            # weighted average of the initial and intermediate derivatives to estimate the next state\n",
    "            x = tuple(map(lambda x,xdot,xdoti:x+(.25*dt)*(xdot+3*xdoti),x,xdot,xdoti))\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    return f\n",
    "\n",
    "# function to minimize the loss\n",
    "def Optimize(loss,args,niter=5):\n",
    "    # loss: function to compute the loss given the current set of parameters (args)\n",
    "    # args: p0\n",
    "    optimizer = torch.optim.LBFGS(args)\n",
    "    losses = []\n",
    "    print('performing optimization...')\n",
    "    # repeatedly adjusts the parameters to minimize the loss function\n",
    "    for i in range(niter):\n",
    "        print(\"iteration \",i+1,\"/\",niter)\n",
    "        def closure():\n",
    "            # reset optimizer gradients to 0 (previous data doesn't affect the current update)\n",
    "            optimizer.zero_grad()\n",
    "            # compute loss\n",
    "            L = loss(*args)\n",
    "            losses.append(L.item())\n",
    "            # backprop to compute the gradients of the loss w.r.t the parameters\n",
    "            L.backward()\n",
    "            \n",
    "            return L\n",
    "        \n",
    "        # update optimizer parameters based on the loss\n",
    "        optimizer.step(closure)\n",
    "        \n",
    "    print(\"Done.\")\n",
    "\n",
    "    return args, losses\n",
    "\n",
    "def Optimize_with_vis(loss, args, niter=10):\n",
    "    optimizer = torch.optim.LBFGS(args)\n",
    "    losses = []\n",
    "    print('Performing optimization with visualization...')\n",
    "    for i in range(niter):\n",
    "        print(\"Iteration\", i+1, \"of\", niter)\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            L = loss(*args)\n",
    "            losses.append(L.item())\n",
    "            L.backward()\n",
    "            return L\n",
    "        optimizer.step(closure)\n",
    "\n",
    "        # Create clones of current momentum and source that require grad,\n",
    "        # so that Shooting (which calls autograd.grad) works correctly.\n",
    "        p_vis = args[0].detach().clone().requires_grad_()\n",
    "        q_vis = q0.detach().clone().requires_grad_()\n",
    "        \n",
    "        # Optionally, compute the deformed shape:\n",
    "        p_current, q_current = Shooting(p_vis, q_vis, Kv)\n",
    "        \n",
    "        # Visualize using the PlotRes3D function:\n",
    "        filename = f\"deformation_iter_{i+1}.html\"\n",
    "        PlotRes3D(VS,FS,VT,FT, filename)(q_vis, p_vis, Kv, src_opacity=0, tgt_opacity=0, def_opacity=1, showgrid=False)\n",
    "        \n",
    "    print(\"Optimization done.\")\n",
    "    \n",
    "    return args, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd0bb7b-640c-4ae5-8ece-574e752b912e",
   "metadata": {},
   "source": [
    "### Implementation of LDDMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e970a22-f0e0-471a-9f9f-6516f32a2801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function of momentum p and position q to represents the total energy of the system\n",
    "# measures the energy associated with the deformation, using the kernel K \n",
    "# to mediate the influence of points on each other.\n",
    "def Hamiltonian(K):\n",
    "    def H(p,q):\n",
    "        return .5*(p*K(q,q,p)).sum()\n",
    "        \n",
    "    return H\n",
    "\n",
    "# builds the Hamiltonian system that needs to be solved during the \"shooting\" process\n",
    "# calculates the gradients of the Hamiltonian with respect to p and q, \n",
    "# which represent the rates of change of these quantities\n",
    "# the system is defined by -Gq, Gp (gradients)\n",
    "def HamiltonianSystem(K):\n",
    "    H = Hamiltonian(K)\n",
    "    \n",
    "    def HS(p,q):\n",
    "        Gp,Gq = grad(H(p,q),(p,q), create_graph=True)\n",
    "        \n",
    "        return -Gq,Gp\n",
    "        \n",
    "    return HS\n",
    "\n",
    "# integrates the Hamiltonian system over time to find the end state (p, q) \n",
    "# starting from initial conditions (p0, q0)\n",
    "def Shooting(p0,q0,K,deltat=1.0,Integrator=RalstonIntegrator()):\n",
    "    return Integrator(HamiltonianSystem(K),(p0,q0),deltat)\n",
    "\n",
    "# intégration des équations de flot\n",
    "def Flow(x0,p0,q0,K,deltat=1.0,Integrator=RalstonIntegrator()):\n",
    "    HS = HamiltonianSystem(K)\n",
    "    \n",
    "    def FlowEq(x,p,q):\n",
    "        return (K(x,q,p),)+HS(p,q)\n",
    "        \n",
    "    return Integrator(FlowEq,(x0,p0,q0),deltat)[0]\n",
    "\n",
    "# defines the loss function to be minimized, \n",
    "# combining the Hamiltonian (energy of the deformation) \n",
    "# and a data attachment loss \n",
    "def LDDMMloss(q0,K,dataloss,gamma=0.):\n",
    "    # dataloss: measures the discrepancy between the deformed source shape and the target shape\n",
    "    # q0: initial configuration of the source shape\n",
    "    # K: kernel function\n",
    "    # gamma: regularization parameter\n",
    "    def loss(p0):\n",
    "        # finding p0 that minimizes the loss\n",
    "        # p, q: final momentum and deformed shape after the shooting process\n",
    "        p,q = Shooting(p0,q0,K)\n",
    "        # Hamiltonian(K): computes the energy of the initial configuration q0 with the initial momentum p0. \n",
    "        # This represents the energy required to deform the shape regularized by gamma\n",
    "        # dataloss(q): computes the mismatch between the final deformed shape q and the target\n",
    "        return gamma * Hamiltonian(K)(p0,q0) + dataloss(q)\n",
    "    \n",
    "    ############################# ToDo #############################\n",
    "    # when adding contours use the flow function, set deltat parameter\n",
    "    # flow -> dataloss for curve -> flow\n",
    "    # extract contours and get corresponding coordinates in 3D\n",
    "    ###############################################################\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c6ecea-a6ab-4997-a5ef-3e9f066ab97c",
   "metadata": {},
   "source": [
    "### Data attachment functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc9602a4-5df8-4b34-9555-3c9e43a3ca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data attachment function for landmarks\n",
    "def losslmk(z):\n",
    "    def loss(q):\n",
    "        return ((q-z)**2).sum()\n",
    "    return loss\n",
    "\n",
    "# data attachment function for point clouds via the measurement model\n",
    "def lossmeas(z,Kw):\n",
    "    nz = z.shape[0]\n",
    "    wz = torch.ones(nz,1)\n",
    "    cst = (1/nz**2)*Kw(z,z,wz).sum()\n",
    "    def loss(q):\n",
    "        nq = q.shape[0]\n",
    "        wq = torch.ones(nq,1)\n",
    "        return cst + (1/nq**2)*Kw(q,q,wq).sum() + (-2/(nq*nz))*Kw(q,z,wz).sum()\n",
    "    return loss\n",
    "\n",
    "# data attachment function for point clouds via regularized optimal transport\n",
    "# (requires geomloss package)\n",
    "def loss_OT(z):\n",
    "    from geomloss import SamplesLoss\n",
    "    loss_ = SamplesLoss()\n",
    "    nz = z.shape[0]\n",
    "    wz = torch.ones(nz,1)\n",
    "    def loss(q):\n",
    "        nq = q.shape[0]\n",
    "        wq = torch.ones(nq,1)\n",
    "        return loss_(wq,q,wz,z)\n",
    "    return loss\n",
    "\n",
    "# data attachment function for triangulated surfaces, varifold model\n",
    "# focuses on matching geometric features like positions and normals without requiring explicit \n",
    "# point correspondence. this function is useful when the exact matching of points between shapes \n",
    "# is infeasible or not desired\n",
    "def lossVarifoldSurf(FS,VT,FT,K):\n",
    "    # VT: coordinates of the points of the target surface\n",
    "    # FS,FT: indices of the triangles of the source and target surfaces\n",
    "    # K: varifold kernel\n",
    "    \n",
    "    # compute centers (C), normals (N), and areas (L) of the triangles for a given surface\n",
    "    # based on vertices V and faces F\n",
    "    def CompCLNn(F,V):\n",
    "        # V0, V1, V2: vertices of each triangle\n",
    "        # center(C) of each triangle is calculated as the average of its vertices\n",
    "        # normal(N): taking the cross product of two edges of the triangle, which is then normalized\n",
    "        # area(L): length of the normal vector before normalization\n",
    "        V0, V1, V2 = V.index_select(0,F[:,0]), V.index_select(0,F[:,1]), V.index_select(0,F[:,2])\n",
    "        C, N = .5*(V0+V1+V2), .5*torch.linalg.cross(V1-V0,V2-V0)\n",
    "        L = (N**2).sum(dim=1)[:,None].sqrt()\n",
    "        \n",
    "        return C,L,N/L\n",
    "    \n",
    "    CT,LT,NTn = CompCLNn(FT,VT)\n",
    "    # self-interaction term for the target surface using the varifold kernel  K\n",
    "    cst = (LT*K(CT,CT,NTn,NTn,LT)).sum()\n",
    "    \n",
    "    # calculates the varifold distance between the source and target surfaces\n",
    "    \n",
    "    # loss is formulated as the sum of the source self-interaction and the \n",
    "    # target self-interaction (cst), minus twice the cross term (interaction between their geometric features)\n",
    "    # the intuition is to minimize the difference in geometric features (both position and direction of normals) \n",
    "    # between the source and target surfaces, thereby aligning them\n",
    "    def loss(VS):\n",
    "        CS,LS,NSn = CompCLNn(FS,VS)\n",
    "        \n",
    "        return cst + (LS*K(CS,CS,NSn,NSn,LS)).sum() - 2*(LS*K(CS,CT,NSn,NTn,LT)).sum()\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# data attachment function for curves, varifolds model\n",
    "def lossVarifoldCurve(FS, VT, FT, K):\n",
    "    def get_center_length_tangents(F, V):\n",
    "        V0, V1 = V.index_select(0, F[:, 0]), V.index_select(0, F[:, 1])\n",
    "        centers, tangents = .5*(V0+V1), V1-V0\n",
    "        length = (tangents**2).sum(dim=1)[:, None].sqrt()\n",
    "        return centers, length, tangents / length\n",
    "    CT, LT, TTn = get_center_length_tangents(FT, VT)\n",
    "    cst = (LT * K(CT, CT, TTn, TTn, LT)).sum()\n",
    "    def loss(VS):\n",
    "        CS, LS, TSn = get_center_length_tangents(FS, VS)\n",
    "        return cst + (LS * K(CS, CS, TSn, TSn, LS)).sum() - 2 * (LS * K(CS, CT, TSn, TTn, LT)).sum()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba2c78f-57a2-47ec-a981-2b9a6498a371",
   "metadata": {},
   "source": [
    "### Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7ab5eea-a840-4fde-bb29-ffedbb0d0152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result display function for landmark or point cloud data\n",
    "def PlotRes2D(z, pts=None):\n",
    "    def plotfun(q0,p0,Kv, showgrid=True):\n",
    "        p,q = Shooting(p0,q0,Kv)\n",
    "        q0np, qnp = q0.data.numpy(), q.data.numpy()\n",
    "        q0np, qnp, znp = q0.data.numpy(), q.data.numpy(), z.data.numpy()\n",
    "        plt.plot(znp[:,0],znp[:,1],'.');\n",
    "        plt.plot(q0np[:,0],q0np[:,1],'+');\n",
    "        plt.plot(qnp[:,0],qnp[:,1],'o');\n",
    "        plt.axis('equal');\n",
    "        if showgrid:\n",
    "            X = get_def_grid(p0,q0,Kv)\n",
    "            plt.plot(X[0],X[1],'k',linewidth=.25);\n",
    "            plt.plot(X[0].T,X[1].T,'k',linewidth=.25); \n",
    "        n,d = q0.shape\n",
    "        nt = 20\n",
    "        Q = np.zeros((n,d,nt))\n",
    "        for i in range(nt):\n",
    "            t = i/(nt-1)\n",
    "            Q[:,:,i] = Shooting(t*p0,q0,Kv)[1].data.numpy()\n",
    "        plt.plot(Q[:,0,:].T,Q[:,1,:].T,'y');\n",
    "        if type(pts)!=type(None):\n",
    "            phipts = Flow(pts,p0,q0,Kv).data\n",
    "            plt.plot(phipts.numpy()[:,0],phipts.numpy()[:,1],'.b',markersize=.1);\n",
    "    return plotfun\n",
    "\n",
    "# display function for triangulated surface type data\n",
    "def PlotRes3D(VS, FS, VT, FT, filename=\"deformation.html\"):\n",
    "    def plotfun(q0, p0, Kv, src_opacity=1, tgt_opacity=1, def_opacity=1, showgrid=True):\n",
    "        # q0, p0: Initial vertices and momenta (optimized) for the source shape\n",
    "        # simulate the deformation process and compute the final deformed shape q\n",
    "        p,q = Shooting(p0,q0,Kv)\n",
    "        # q0np, qnp: numpy arrays of the initial and final vertex positions\n",
    "        q0np, qnp = q0.data.numpy(), q.data.numpy()\n",
    "        # numpy arrays of source and target faces\n",
    "        FSnp,VTnp, FTnp = FS.data.numpy(),  VT.data.numpy(), FT.data.numpy() \n",
    "        if use_pyvista:\n",
    "            p = pv.Plotter()\n",
    "            opacity = 1\n",
    "            # mesh for the initial shape\n",
    "            p.add_mesh(surf_to_pv(q0np,FSnp), color='lightblue', opacity=src_opacity)\n",
    "            # mesh for the deformed shape\n",
    "            p.add_mesh(surf_to_pv(qnp,FSnp), color='lightcoral', opacity=def_opacity)\n",
    "            # mesh for target shape\n",
    "            p.add_mesh(surf_to_pv(VTnp,FTnp), color='lightgreen', opacity=tgt_opacity)\n",
    "            if showgrid:\n",
    "                ng = 20\n",
    "                X = get_def_grid(p0,q0,Kv,ng=ng)\n",
    "                for k in range(3):\n",
    "                    for i in range(ng):\n",
    "                        for j in range(ng):\n",
    "                            p.add_mesh(lines_from_points(X[:,i,j,:].T))\n",
    "                    X = X.transpose((0,2,3,1))\n",
    "            # p.show()\n",
    "            p.export_html(filename)\n",
    "            p.close()\n",
    "        else:\n",
    "            fig = plt.figure();\n",
    "            plt.axis('off')\n",
    "            plt.title('LDDMM matching example')     \n",
    "#             ax = Axes3D(fig, auto_add_to_figure=False)\n",
    "            ax = Axes3D(fig)\n",
    "            # triangular mesh for the initial shape\n",
    "            ax.plot_trisurf(q0np[:,0],q0np[:,1],q0np[:,2],triangles=FSnp,alpha=.5)\n",
    "            # triangular mesh for the deformed shape\n",
    "            ax.plot_trisurf(qnp[:,0],qnp[:,1],qnp[:,2],triangles=FSnp,alpha=.5)\n",
    "            # triangular mesh for the target shape\n",
    "            ax.plot_trisurf(VTnp[:,0],VTnp[:,1],VTnp[:,2],triangles=FTnp,alpha=.5)\n",
    "            if showgrid:\n",
    "                ng = 20\n",
    "                X = get_def_grid(p0,q0,Kv,ng=ng)\n",
    "                for k in range(3):\n",
    "                    for i in range(ng):\n",
    "                        for j in range(ng):\n",
    "                            ax.plot(X[0,i,j,:],X[1,i,j,:],X[2,i,j,:],'k',linewidth=.25);\n",
    "                    X = X.transpose((0,2,3,1))\n",
    "            fig.add_axes(ax)\n",
    "    return plotfun\n",
    "\n",
    "def get_def_grid(p0,q0,Kv,ng=50):\n",
    "    d = p0.shape[1]\n",
    "    p,q = Shooting(p0,q0,Kv)\n",
    "    q0np, qnp = q0.data.numpy(), q.data.numpy()\n",
    "    q0np, qnp = q0.data.numpy(), q.data.numpy()\n",
    "    # calculates the minimum (a) and maximum (b) coordinates for the vertices in the \n",
    "    # initial (q0) and final (q) positions to establish the bounds of the grid\n",
    "    a = list(np.min(np.vstack((q0np[:,k],qnp[:,k]))) for k in range(d))\n",
    "    b = list(np.max(np.vstack((q0np[:,k],qnp[:,k]))) for k in range(d))\n",
    "    # expands these bounds by 20% to ensure the grid extends slightly beyond the \n",
    "    # immediate area covered by the initial and deformed shapes\n",
    "    sz = 0.2\n",
    "    lsp = list(np.linspace(a[k]-sz*(b[k]-a[k]),b[k]+sz*(b[k]-a[k]),ng,dtype=np.float32) for k in range(d))\n",
    "    X = np.meshgrid(*lsp)\n",
    "    x = np.concatenate(list(X[k].reshape(ng**d,1) for k in range(d)),axis=1)\n",
    "    # transform grid (x) according to the LDDMM mapping\n",
    "    # Flow():  integrates how each point in the grid moves under the transformation \n",
    "    # defined by Kv, p0, and q0. This step effectively applies the diffeomorphic map to the entire grid\n",
    "    phix = Flow(torch.from_numpy(x),p0,q0,Kv).detach().numpy()\n",
    "    X = phix.transpose().reshape([d]+[ng]*d)\n",
    "    return X\n",
    "\n",
    "def lines_from_points(points):\n",
    "    import pyvista as pv\n",
    "    \"\"\"Given an array of points, make a line set\"\"\"\n",
    "    poly = pv.PolyData()\n",
    "    poly.points = points\n",
    "    cells = np.full((len(points) - 1, 3), 2, dtype=np.int_)\n",
    "    cells[:, 1] = np.arange(0, len(points) - 1, dtype=np.int_)\n",
    "    cells[:, 2] = np.arange(1, len(points), dtype=np.int_)\n",
    "    poly.lines = cells\n",
    "    return poly\n",
    "\n",
    "def surf_to_pv(V,F):\n",
    "    nf = F.shape[0]\n",
    "    F = np.hstack((np.ones((nf,1),dtype=\"int\")*3,F))\n",
    "    F = F.flatten()\n",
    "    surf = pv.PolyData(V,F)\n",
    "    return surf\n",
    "\n",
    "# fonction d'affichage pour des données de type surface triangulée\n",
    "def PlotResSurf(VS,FS,VT,FT):\n",
    "    def plotfun(q0,p0,Kv):\n",
    "        fig = plt.figure();\n",
    "        plt.axis('off')\n",
    "        plt.title('LDDMM matching example')  \n",
    "        p,q = Shooting(p0,q0,Kv)\n",
    "        q0np, qnp = q0.data.numpy(), q.data.numpy()\n",
    "        FSnp,VTnp, FTnp = FS.data.numpy(),  VT.data.numpy(), FT.data.numpy()    \n",
    "        ax = Axes3D(fig, auto_add_to_figure=False)\n",
    "        ax.plot_trisurf(q0np[:,0],q0np[:,1],q0np[:,2],triangles=FSnp,alpha=.5)\n",
    "        ax.plot_trisurf(qnp[:,0],qnp[:,1],qnp[:,2],triangles=FSnp,alpha=.5)\n",
    "        ax.plot_trisurf(VTnp[:,0],VTnp[:,1],VTnp[:,2],triangles=FTnp,alpha=.5)\n",
    "        fig.add_axes(ax)\n",
    "    return plotfun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dafbb4-4de8-495c-8c36-b3f718caf3f7",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "368ccaea-bbb1-4a5c-8ace-1f682cc590ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load mesh and convert to tensors\n",
    "def load_mesh_as_tensors(filepath):\n",
    "    # Load the mesh\n",
    "    mesh = trimesh.load(filepath, process=False)\n",
    "    \n",
    "    # Convert vertices and faces to PyTorch tensors\n",
    "    vertices = torch.tensor(mesh.vertices, dtype=torch.float32)\n",
    "    faces = torch.tensor(mesh.faces, dtype=torch.long)\n",
    "    \n",
    "    return vertices, faces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066e6eb9-82b8-4637-9afb-7caf8e4ac85b",
   "metadata": {},
   "source": [
    "### Surface matching with LDDMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca7fe46d-3900-4f0a-ba91-3e3a36819e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing optimization with visualization...\n",
      "Iteration 1 of 10\n",
      "Iteration 2 of 10\n",
      "Iteration 3 of 10\n",
      "Iteration 4 of 10\n",
      "Iteration 5 of 10\n",
      "Iteration 6 of 10\n",
      "Iteration 7 of 10\n",
      "Iteration 8 of 10\n",
      "Iteration 9 of 10\n",
      "Iteration 10 of 10\n",
      "Optimization done.\n"
     ]
    }
   ],
   "source": [
    "VS, FS = load_mesh_as_tensors('../../Data/surface_meshes/segmentation_a_mesh_500.ply')\n",
    "VT, FT = load_mesh_as_tensors('../../Data/surface_meshes/segmentation_r_mesh_500.ply')\n",
    "\n",
    "# Save the tensors into a .pt file\n",
    "torch.save((VS, FS, VT, FT), 'a-r_mesh.pt')\n",
    "\n",
    "VS,FS,VT,FT = torch.load('a-r_mesh.pt') \n",
    "q0 = VS.clone().detach().requires_grad_(True)\n",
    "Kv = GaussKernel(sigma=20)\n",
    "# multiscale kernel\n",
    "Dataloss = lossVarifoldSurf(FS,VT,FT,GaussLinKernel(sigma=20)) # try smaller values (15-20)\n",
    "loss = LDDMMloss(q0,Kv,Dataloss, gamma=0.1)\n",
    "p0 = torch.zeros(q0.shape, requires_grad=True)\n",
    "\n",
    "p0, losses = Optimize_with_vis(loss,[p0],niter=10) # 100 iterations\n",
    "PlotRes3D(VS,FS,VT,FT, filename=\"src.html\")(q0,p0[0],Kv,src_opacity=1,tgt_opacity=0,def_opacity=0, showgrid=False)\n",
    "# PlotRes3D(VS,FS,VT,FT)(q0,p0[0],Kv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4ef8763-564b-4e4e-b16d-19dbbde3474a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce401e7928d48e1b4bdc87961933035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:56162/index.html?ui=P_0x18d6592a300_0&reconnect=auto\" class=\"pyvis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba6c203583b476daa00a464293273c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:56162/index.html?ui=P_0x18d5b3510d0_0&reconnect=auto\" class=\"pyvis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb20b1f856941089411d88057e04463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:56162/index.html?ui=P_0x18d5c6fba40_0&reconnect=auto\" class=\"pyvis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot source shape\n",
    "PlotRes3D(VS,FS,VT,FT, filename=\"src.html\")(q0,p0[0],Kv,src_opacity=1,tgt_opacity=0,def_opacity=0, showgrid=False)\n",
    "\n",
    "# plot target shape\n",
    "PlotRes3D(VS,FS,VT,FT, filename=\"tgt.html\")(q0,p0[0],Kv,src_opacity=0,tgt_opacity=1,def_opacity=0, showgrid=False)\n",
    "\n",
    "# plot deformed shape\n",
    "PlotRes3D(VS,FS,VT,FT, filename=\"deformation.html\")(q0,p0[0],Kv,src_opacity=0,tgt_opacity=0,def_opacity=1, showgrid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e086d46-9e30-42a0-bf77-b425b75155a3",
   "metadata": {},
   "source": [
    "### Constrained LDDMM\n",
    "\n",
    "The approach:\n",
    "1. Modify the integrator to store intermediate states (history)\n",
    "2. Extract the midsagittal slice (2D) from the deformed shape\n",
    "3. Apply the transformation\n",
    "4. Compute a loss (say contour loss) that compares these transformed 2D points to the corresponding rtMRI contours. \n",
    "5. Combine the “contour loss” with the original LDDMM loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5906bd-f65f-4f48-8cab-2c4c82b5d9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ralston Integrator with History: returns a list of (p,q) states.\n",
    "def RalstonIntegratorWithHistory(nt=10):\n",
    "    def f(ODESystem, x0, deltat=1.0):\n",
    "        history = []\n",
    "        # x0: initial conditions (p0, q0)\n",
    "        # deltat: total integration time\n",
    "        x = tuple([x.clone() for x in x0])\n",
    "        history.append(x)  # store the initial state at t = 0.\n",
    "        dt = deltat / nt\n",
    "        for i in range(nt):\n",
    "            xdot = ODESystem(*x)\n",
    "            xi = tuple([xi_val + (2 * dt / 3) * xdot_val for xi_val, xdot_val in zip(x, xdot)])\n",
    "            xdoti = ODESystem(*xi)\n",
    "            x = tuple([xi_val + (0.25 * dt) * (xdot_val + 3 * xdoti_val)\n",
    "                       for xi_val, xdot_val, xdoti_val in zip(x, xdot, xdoti)])\n",
    "            history.append(x)\n",
    "            \n",
    "        return history  # list of states at each time step\n",
    "        \n",
    "    return f\n",
    "\n",
    "# Compute and return the deformed shape history (q states).\n",
    "def ShootingHistory(p0, q0, K, deltat=1.0, Integrator=RalstonIntegratorWithHistory()):\n",
    "    history = Integrator(HamiltonianSystem(K), (p0, q0), deltat)\n",
    "    # Extract the q (shape) component from each (p,q) state.\n",
    "    q_history = [state[1] for state in history]\n",
    "    \n",
    "    return q_history\n",
    "\n",
    "# Extract the midsagittal slice from the 3D shape.\n",
    "def extract_midsagittal_slice(vertices):\n",
    "    ## ToDo: follow the implementation done in MATLAB\n",
    "    return slice_coords\n",
    "    \n",
    "# Apply transformations to the extracted 2D slice so that it matches the rtMRI frame coordinates.\n",
    "def apply_transformation(points, transformation_matrix, translation_vector):\n",
    "    ## ToDo: follow the Python implementation and apply transformation\n",
    "    return trandformed_points\n",
    "\n",
    "# Compute the contour loss over the history of deformed shapes.\n",
    "# For each intermediate deformed shape, extract the midsagittal slice,\n",
    "# apply the transformation, and compare with the corresponding rtMRI contour.\n",
    "def contour_loss(q_history, rtMRI_contours, transformation_matrix, translation_vector):\n",
    "    # q_history: list of deformed shapes (tensor of shape (N, 3))\n",
    "    # rtMRI_contours: list of 2D contour tensors (each of shape (M, 2)) for each time step (ideal length = 11)\n",
    "    total_loss = 0.0\n",
    "    num = len(q_history)\n",
    "    for q, contour_rt in zip(q_history, rtMRI_contours):\n",
    "        slice_2d = extract_midsagittal_slice(q)\n",
    "        slice_2d_transformed = apply_transformation(slice_2d, transformation_matrix, translation_vector)\n",
    "        \n",
    "        ## ToDo: Loss calculation when the number of points are different and no correspondance\n",
    "        ## Chamfer distance?\n",
    "        loss_i = ((slice_2d_transformed - contour_rt.to(slice_2d_trans.device))**2).mean() # Cannot use MSE\n",
    "        \n",
    "        total_loss += loss_i\n",
    "        \n",
    "    return total_loss / num\n",
    "\n",
    "# Extended LDDMM loss function that includes the contour loss.\n",
    "# Contour loss is weighted by a parameter lambda_contour\n",
    "def LDDMMloss_extended(q0, K, dataloss, rtMRI_contours, transformation_matrix, translation_vector, gamma=0., lambda_contour=1.0):\n",
    "    # q0: initial source shape (3D, tensor)\n",
    "    # K: kernel function \n",
    "    # dataloss: function computing data attachment loss between deformed shape and target 3D shape\n",
    "    # rtMRI_contours: list of rtMRI contour tensors each with shape (M,2)\n",
    "    # transformation_matrix, translation_vector: parameters to align the extracted 2D slice with rtMRI coordinates\n",
    "    def loss(p0):\n",
    "        # Compute the final deformed shape using the original existing Shooting function.\n",
    "        p, q_final = Shooting(p0, q0, K)\n",
    "        base_loss = gamma * Hamiltonian(K)(p0, q0) + dataloss(q_final)\n",
    "        \n",
    "        # Compute the intermediate deformed shapes (history) using the modified integrator.\n",
    "        q_history = ShootingHistory(p0, q0, K)\n",
    "        contour_loss_val = contour_loss(q_history, rtMRI_contours, transformation_matrix, translation_vector)\n",
    "        \n",
    "        return base_loss + lambda_contour * contour_loss_val\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb622c6-4409-4336-a238-8a864591f787",
   "metadata": {},
   "outputs": [],
   "source": [
    "VS, FS = load_mesh_as_tensors('../../Data/surface_meshes/segmentation_a_mesh_500.ply')\n",
    "VT, FT = load_mesh_as_tensors('../../Data/surface_meshes/segmentation_r_mesh_500.ply')\n",
    "\n",
    "# Save the tensors into a .pt file\n",
    "torch.save((VS, FS, VT, FT), 'a-r_mesh.pt')\n",
    "\n",
    "VS,FS,VT,FT = torch.load('a-r_mesh.pt') \n",
    "q0 = VS.clone().detach().requires_grad_(True)\n",
    "Kv = GaussKernel(sigma=20)\n",
    "\n",
    "rtMRI_contours = []\n",
    "transformation_matrix = []\n",
    "translation_vector = []\n",
    "\n",
    "Dataloss = lossVarifoldSurf(FS,VT,FT,GaussLinKernel(sigma=20)) \n",
    "# loss = LDDMMloss(q0,Kv,Dataloss)\n",
    "loss = LDDMMloss_extended(q0, Kv, dataloss, rtMRI_contours, transformation_matrix, translation_vector, gamma=0.01, lambda_contour=1.0)\n",
    "\n",
    "p0 = torch.zeros(q0.shape, requires_grad=True)\n",
    "p0, losses = Optimize(loss,[p0],niter=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
